{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4118d05",
   "metadata": {},
   "source": [
    "## Loading the 20 newsgroups dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b7dc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c90c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c4b8e6",
   "metadata": {},
   "source": [
    "### Chargement de la liste des fichiers correspondant à ces catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeb30042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Cache loading failed\n",
      "________________________________________________________________________________\n",
      "No module named 'sklearn.utils._bunch'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c701ba",
   "metadata": {},
   "source": [
    "#### Le dataset de retour est un scikit-learn bunch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23fe578",
   "metadata": {},
   "source": [
    "### liste des noms de catégories demandés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40e9a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171c475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f269cfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b2eb5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6e801ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e33cacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f31a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "sci.med\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34653ec0",
   "metadata": {},
   "source": [
    "* Le prétraitement du texte, la segmentation et le filtrage des mots vides sont tous inclus dans CountVectorizer, qui crée un dictionnaire d'entités et transforme les documents en vecteurs d'entités\n",
    "* CountVectorizer prend en charge le nombre de N-grammes de mots ou de caractères consécutifs. Une fois ajusté, le vectoriseur a construit un dictionnaire d'indices de caractéristiques\n",
    "* N-grammes : le nombre de mot consideré comme un token (par ex : 2-grammes contient deux mots qui représente un token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24901134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ef0217b",
   "metadata": {},
   "source": [
    "* La valeur d'indice d'un mot dans le vocabulaire est liée à sa fréquence dans l'ensemble du corpus d'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca513ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c60928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5eb97b6c",
   "metadata": {},
   "source": [
    "### Normalization : TfidfTransformer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41e136aa",
   "metadata": {},
   "source": [
    "* L'objectif d'utiliser tf-idf au lieu des fréquences brutes d'occurrence d'un jeton dans un document donné est de réduire l'impact des jetons qui se produisent très fréquemment dans un corpus donné et qui sont donc empiriquement moins informatifs que les caractéristiques qui se produisent dans un petite fraction du corpus de formation.\n",
    "\n",
    "* Pour éviter les écarts potentiels, il suffit de diviser le nombre d'occurrences de chaque mot dans un document par le nombre total de mots dans le document : ces nouvelles fonctionnalités sont appelées **tf Term Frequencies**.\n",
    "\n",
    "* La réduction d'échelle est appelée **tf–idf** pour « **Term Frequency times Inverse Document Frequency** ».\n",
    "\n",
    "* **tf** et **tf–idf** peuvent être calculés comme suit en utilisant **TfidfTransformer**. \n",
    "\n",
    "* Le corpus est l'ensemble des documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "029360e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9b8c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8edce54",
   "metadata": {},
   "source": [
    "### Inférence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81103cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "872e4a95",
   "metadata": {},
   "source": [
    "### Création d'un Pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f03da99d",
   "metadata": {},
   "source": [
    "* C'est un estimateur qui va contenir l'ensemble de nos traitements précedents : pretraitement, normalisation, et le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63baae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB()),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3302e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2267fe6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8348868175765646"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "512b1460",
   "metadata": {},
   "source": [
    "### Création d'un nouveau Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e8c8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.10.4' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                           alpha=1e-3, random_state=42,\n",
    "                           max_iter=5, tol=None)),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "826b9344",
   "metadata": {},
   "source": [
    "* Affichage des valeurs des differentes metrics de classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886dca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "     target_names=twenty_test.target_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69e24351",
   "metadata": {},
   "source": [
    "* Affichage de la matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c77ca64",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd4770cb",
   "metadata": {},
   "source": [
    "### Utilisation de GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58b7f83a",
   "metadata": {},
   "source": [
    "* La méthode GridSearchCV est utilisée pour obtenir les paramètres optimaux du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf733d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "     'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "     'tfidf__use_idf': (True, False),\n",
    "     'clf__alpha': (1e-2, 1e-3),\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753af116",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58244daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77a2b034",
   "metadata": {},
   "source": [
    "* Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03e0dc76",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m twenty_train\u001b[38;5;241m.\u001b[39mtarget_names[\u001b[43mgs_clf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGod is love\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gs_clf' is not defined"
     ]
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9f8a0f4",
   "metadata": {},
   "source": [
    "* Affichage du meilleur score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13bf8d6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgs_clf\u001b[49m\u001b[38;5;241m.\u001b[39mbest_score_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gs_clf' is not defined"
     ]
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "301b7e72",
   "metadata": {},
   "source": [
    "* Affichage des paramètres optimaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "     print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f63cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde330b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642701fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "0187438eba99bd7a5255dd0c491934e3157b8001b931565cd79de712549588d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
